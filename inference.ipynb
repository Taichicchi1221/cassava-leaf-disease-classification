{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020968,
     "end_time": "2021-02-14T15:09:28.976571",
     "exception": false,
     "start_time": "2021-02-14T15:09:28.955603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "学習用notebook → https://www.kaggle.com/hutch1221/training-cassava-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018486,
     "end_time": "2021-02-14T15:09:29.014714",
     "exception": false,
     "start_time": "2021-02-14T15:09:28.996228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 変更仕様(from baseline)\n",
    "* augmentationのクラス化、private dataset に退避 https://github.com/Taichicchi1221/tf-image-classification\n",
    "* random_rotation, FMixの実装\n",
    "* bi-tempered lossを追加(LOSS_TYPE=\"BTL\"で指定) https://github.com/Diulhio/bitemperedloss-tf\n",
    "* External datasetを追加（2019年cassavaコンペのもの）https://www.kaggle.com/c/cassava-disease\n",
    "* TTAの実装(oofで評価)\n",
    "* Image Normalization実装（フラグ\"IMAGE_NORMALIZATION\"で管理）\n",
    "* ViTモデルの指定（バッチサイズ小さめにしないとダメ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:09:29.057139Z",
     "iopub.status.busy": "2021-02-14T15:09:29.056414Z",
     "iopub.status.idle": "2021-02-14T15:09:29.060647Z",
     "shell.execute_reply": "2021-02-14T15:09:29.060093Z"
    },
    "papermill": {
     "duration": 0.027298,
     "end_time": "2021-02-14T15:09:29.060841",
     "exception": false,
     "start_time": "2021-02-14T15:09:29.033543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 上記notebook(学習用)の結果が入ったdirectoryを指定\n",
    "INPUT_DIR = \"../input/result-exp40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:09:29.104208Z",
     "iopub.status.busy": "2021-02-14T15:09:29.102709Z",
     "iopub.status.idle": "2021-02-14T15:09:29.104797Z",
     "shell.execute_reply": "2021-02-14T15:09:29.105791Z"
    },
    "papermill": {
     "duration": 0.026043,
     "end_time": "2021-02-14T15:09:29.105965",
     "exception": false,
     "start_time": "2021-02-14T15:09:29.079922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:09:29.158097Z",
     "iopub.status.busy": "2021-02-14T15:09:29.157473Z",
     "iopub.status.idle": "2021-02-14T15:11:44.750688Z",
     "shell.execute_reply": "2021-02-14T15:11:44.749977Z"
    },
    "papermill": {
     "duration": 135.625652,
     "end_time": "2021-02-14T15:11:44.750915",
     "exception": false,
     "start_time": "2021-02-14T15:09:29.125263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q /kaggle/input/keras-efficientnet-whl/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install -q /kaggle/input/keras-efficientnet-whl/efficientnet-1.1.1-py3-none-any.whl\n",
    "!pip install -q /kaggle/input/keras-pretrained-imagenet-weights/image_classifiers-1.0.0-py3-none-any.whl\n",
    "!pip install -q /kaggle/input/vit-keras/validators-0.18.2-py3-none-any.whl\n",
    "!pip install -q /kaggle/input/vit-keras/vit_keras-0.0.10-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:44.805492Z",
     "iopub.status.busy": "2021-02-14T15:11:44.804617Z",
     "iopub.status.idle": "2021-02-14T15:11:50.817895Z",
     "shell.execute_reply": "2021-02-14T15:11:50.816730Z"
    },
    "papermill": {
     "duration": 6.041617,
     "end_time": "2021-02-14T15:11:50.818056",
     "exception": false,
     "start_time": "2021-02-14T15:11:44.776439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:50.862557Z",
     "iopub.status.busy": "2021-02-14T15:11:50.861962Z",
     "iopub.status.idle": "2021-02-14T15:11:51.460037Z",
     "shell.execute_reply": "2021-02-14T15:11:51.460584Z"
    },
    "papermill": {
     "duration": 0.622593,
     "end_time": "2021-02-14T15:11:51.460760",
     "exception": false,
     "start_time": "2021-02-14T15:11:50.838167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/kaggle/input/tf-bi-tempered-loss\")\n",
    "from tf_bi_tempered_loss import BiTemperedLogisticLoss\n",
    "import efficientnet.tfkeras as efn\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from vit_keras import vit, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:51.519880Z",
     "iopub.status.busy": "2021-02-14T15:11:51.519250Z",
     "iopub.status.idle": "2021-02-14T15:11:51.546685Z",
     "shell.execute_reply": "2021-02-14T15:11:51.545323Z"
    },
    "papermill": {
     "duration": 0.051567,
     "end_time": "2021-02-14T15:11:51.546848",
     "exception": false,
     "start_time": "2021-02-14T15:11:51.495281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# codes from private dataset\n",
    "sys.path.append(\"/kaggle/input/tf-augmentation-class/\")\n",
    "from augmentation import SingleImageAugmentator, MixImageAugmentator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019677,
     "end_time": "2021-02-14T15:11:51.586457",
     "exception": false,
     "start_time": "2021-02-14T15:11:51.566780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Test TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:51.642634Z",
     "iopub.status.busy": "2021-02-14T15:11:51.641990Z",
     "iopub.status.idle": "2021-02-14T15:11:54.122413Z",
     "shell.execute_reply": "2021-02-14T15:11:54.122892Z"
    },
    "papermill": {
     "duration": 2.517036,
     "end_time": "2021-02-14T15:11:54.123079",
     "exception": false,
     "start_time": "2021-02-14T15:11:51.606043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image samples: 1\n",
      "\n",
      "Writing TFRecord 1 of 15...\n",
      "filename: /kaggle/working/tfrecs/Id_test00-1.tfrec\n",
      "1 samples\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# Create TF Records\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(image, target, image_name):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'target': _int64_feature(target),\n",
    "        'image_name': _bytes_feature(image_name),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "IMG_PATH = \"/kaggle/input/cassava-leaf-disease-classification/test_images/\"\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\", dtype={\"image_id\": \"object\", \"label\": \"uint8\"})\n",
    "\n",
    "IMGS = os.listdir(IMG_PATH)\n",
    "N_FILES = 15 # split images into 10 files\n",
    "IMG_QUALITY = 100\n",
    "os.makedirs(\"/kaggle/working/tfrecs\", exist_ok = True)\n",
    "\n",
    "print(f'Image samples: {len(IMGS)}')\n",
    "\n",
    "\n",
    "test[\"file\"] = test.index.values%N_FILES\n",
    "test_filenames = []\n",
    "\n",
    "for tfrec_num in range(N_FILES):\n",
    "    samples = test[test['file'] == tfrec_num]\n",
    "    n_samples = len(samples)\n",
    "    if n_samples == 0: break\n",
    "    fname = '/kaggle/working/tfrecs/Id_test%.2i-%i.tfrec'%(tfrec_num, n_samples)\n",
    "    print('\\nWriting TFRecord %i of %i...'%(tfrec_num + 1, N_FILES))\n",
    "    print(f\"filename: {fname}\")\n",
    "    print(f'{n_samples} samples')\n",
    "    test_filenames.append(fname)\n",
    "    with tf.io.TFRecordWriter(fname) as writer:\n",
    "        for row in samples.itertuples():\n",
    "            label = row.label\n",
    "            image_name = row.image_id\n",
    "            img_path = f'{IMG_PATH}{image_name}'\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            img = img[:, 100:700] # center cropping\n",
    "            img = cv2.resize(img, (512, 512))\n",
    "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tobytes()\n",
    "            \n",
    "            example = serialize_example(img, label, str.encode(image_name))\n",
    "            writer.write(example)\n",
    "            \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02067,
     "end_time": "2021-02-14T15:11:54.165519",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.144849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.215813Z",
     "iopub.status.busy": "2021-02-14T15:11:54.215147Z",
     "iopub.status.idle": "2021-02-14T15:11:54.221631Z",
     "shell.execute_reply": "2021-02-14T15:11:54.222103Z"
    },
    "papermill": {
     "duration": 0.035934,
     "end_time": "2021-02-14T15:11:54.222263",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.186329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "        except RuntimeError as e:\n",
    "            # Visible devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "    \n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(\"REPLICAS: \", REPLICAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.270029Z",
     "iopub.status.busy": "2021-02-14T15:11:54.269308Z",
     "iopub.status.idle": "2021-02-14T15:11:54.272450Z",
     "shell.execute_reply": "2021-02-14T15:11:54.271991Z"
    },
    "papermill": {
     "duration": 0.028609,
     "end_time": "2021-02-14T15:11:54.272568",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.243959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=13):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_KERAS'] = '1'\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.319620Z",
     "iopub.status.busy": "2021-02-14T15:11:54.319046Z",
     "iopub.status.idle": "2021-02-14T15:11:54.333964Z",
     "shell.execute_reply": "2021-02-14T15:11:54.333432Z"
    },
    "papermill": {
     "duration": 0.04045,
     "end_time": "2021-02-14T15:11:54.334088",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.293638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EXPERIMENT_TAG': 'exp40', 'DATA_TYPE': 'CROP-RESIZED', 'USE_EXTERNAL_DATA': True, 'SEED': 40, 'NUM_CLASSES': 5, 'CHANNELS': 3, 'IMAGE_SIZE': [512, 512], 'IMAGE_NORMALIZATION': True, 'NORMALIZATION_MEAN': [0.42984136, 0.49624753, 0.3129598], 'NORMALIZATION_STD': [0.21417203, 0.21910103, 0.19542212], 'BATCH_SIZE': 256, 'AUG_BATCH': 64, 'DO_AUG': True, 'RANDOM_FLIP_LEFT_RIGHT': True, 'RANDOM_FLIP_UP_DOWN': True, 'RANDOM_ROTATION': True, 'RANDOM_ROTATION_RANGE': 45, 'RANDOM_ROTATION_FILL_MODE': 'reflect', 'RANDOM_BRIGHTNESS': True, 'RANDOM_BRIGHTNESS_MAX_DELTA': 0.2, 'RANDOM_CONTRAST': False, 'RANDOM_CONTRAST_LOWER': 0.6, 'RANDOM_CONTRAST_UPPER': 1.4, 'RANDOM_HUE': False, 'RANDOM_HUE_MAX_DELTA': 0.07, 'RANDOM_SATURATION': False, 'RANDOM_SATURATION_LOWER': 0.5, 'RANDOM_SATURATION_UPPER': 1.5, 'DO_MIX_AUG': True, 'MIXUP_PROB': 0.0, 'MIXUP_ALPHA': 1.0, 'CUTMIX_PROB': 1.0, 'CUTMIX_ALPHA': 1.0, 'FMIX_PROB': 1.0, 'FMIX_ALPHA': 1.0, 'FMIX_DECAY': 3.0, 'FOLDS': 5, 'FOLDS_SEED': 40, 'EPOCHS': 25, 'EARLY_STOPPING': False, 'ES_MONITOR': 'val_loss', 'ES_MIN_DELTA': 0, 'ES_PATIENCE': 5, 'MC_MONITOR': 'val_loss', 'MODEL_TAG': 'EfficientNetB5', 'INITIAL_WEIGHTS': 'noisy-student', 'FREEZE_BN': True, 'LEARNING_RATE': 0.00024, 'LR_FIRST_DECAY_STEPS': 5, 'LOSS_TYPE': 'BTL', 'LABEL_SMOOTHING': 0.3, 'BI_TEMPERED_LOSS_T1': 0.5, 'BI_TEMPERED_LOSS_T2': 1.5, 'N_ITER': 5, 'TTA': 4, 'MEMBER_NAME': 'Taguchi', 'COMMENT': 'exp40'}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(INPUT_DIR, \"configuration.json\")) as f:\n",
    "    CFG = json.load(f)\n",
    "\n",
    "with open(os.path.join(INPUT_DIR, \"result.json\")) as f:\n",
    "    RESULT = json.load(f)\n",
    "    \n",
    "OUTPUT_DIR = f\"/kaggle/working/{CFG['EXPERIMENT_TAG']}\"\n",
    "\n",
    "INPUT_SHAPE = (*CFG[\"IMAGE_SIZE\"], 3)    \n",
    "\n",
    "print(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022887,
     "end_time": "2021-02-14T15:11:54.378266",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.355379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Base Model Tags\n",
    "* ResNet18\n",
    "* ResNet50\n",
    "* ResNet50V2\n",
    "* ResNet101\n",
    "* ResNet101V2\n",
    "* ResNet152\n",
    "* ResNet152V2\n",
    "* EfficientNetB0\n",
    "* EfficientNetB1\n",
    "* EfficientNetB2\n",
    "* EfficientNetB3\n",
    "* EfficientNetB4\n",
    "* EfficientNetB5\n",
    "* EfficientNetB6\n",
    "* EfficientNetB7\n",
    "* ResNeXt50\n",
    "* ResNeXt101\n",
    "* SeResNet50\n",
    "* SeResNet101\n",
    "* SeResNeXt50\n",
    "* SeResNeXt101\n",
    "* vit_b16\n",
    "* vit_b32\n",
    "* vit_l16\n",
    "* vit_l32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.460908Z",
     "iopub.status.busy": "2021-02-14T15:11:54.438403Z",
     "iopub.status.idle": "2021-02-14T15:11:54.483685Z",
     "shell.execute_reply": "2021-02-14T15:11:54.483153Z"
    },
    "papermill": {
     "duration": 0.080004,
     "end_time": "2021-02-14T15:11:54.483857",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.403853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, model_tag, weights, freeze_bn, input_shape):\n",
    "        self.model_tag = model_tag\n",
    "        self.weights = weights\n",
    "        self.freeze_bn = freeze_bn\n",
    "        self.INPUT_SHAPE = input_shape\n",
    "        self.ERR_MSG_WEIGHT = \"weightの指定が不適です！\"\n",
    "        self.ERR_MSG_MODEL_TAG = \"Model Tagの指定が不適です！\"\n",
    "    def __call__(self):\n",
    "        if self.model_tag == \"ResNet18\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/resnet18_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('resnet18')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"ResNet50\":\n",
    "            if self.weights in [None, \"imagenet\"]:\n",
    "                base_model = tf.keras.applications.ResNet50(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"ResNet50V2\":\n",
    "            if self.weights in [None, \"imagenet\"]:\n",
    "                base_model = tf.keras.applications.ResNet50V2(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"ResNet101\":\n",
    "            if self.weights in [None, \"imagenet\"]:\n",
    "                base_model = tf.keras.applications.ResNet101(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"ResNet101\":\n",
    "            if self.weights in [None, \"imagenet\"]:\n",
    "                base_model = tf.keras.applications.ResNet101V2(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB0\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB0(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB1\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB1(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB2\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB2(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB3\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB3(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB4\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB4(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB5\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB5(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB6\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB6(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"EfficientNetB7\":\n",
    "            if self.weights in [None, \"imagenet\", \"noisy-student\"]:\n",
    "                base_model = efn.EfficientNetB7(input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False, pooling = \"avg\")\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "        elif self.model_tag == \"ResNeXt50\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/resnext50_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('resnext50')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"ResNeXt101\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/resnext101_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('resnext101')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"SeResNet50\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/seresnet50_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('seresnet50')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"SeResNet101\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/seresnet101_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('seresnet101')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"SeResNeXt50\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/seresnext50_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('seresnext50')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"SeResNeXt101\":\n",
    "            if self.weights is None:\n",
    "                pass\n",
    "            elif self.weights == \"imagenet\":\n",
    "                self.weights = \"/kaggle/input/keras-pretrained-imagenet-weights/seresnext101_imagenet_1000_no_top.h5\"\n",
    "            else:\n",
    "                raise NotImplementedError(self.ERR_MSG_WEIGHT)\n",
    "            base_model = tf.keras.Sequential(\n",
    "                    [\n",
    "                        Classifiers.get('seresnext101')[0](input_shape = self.INPUT_SHAPE, weights = self.weights, include_top = False),\n",
    "                        tf.keras.layers.GlobalAveragePooling2D()\n",
    "                    ]\n",
    "                )\n",
    "        elif self.model_tag == \"vit_b16\":\n",
    "            base_model = vit.vit_b16(\n",
    "                image_size=self.INPUT_SHAPE[0],\n",
    "                activation='softmax',\n",
    "                pretrained=(self.weights == \"imagenet\"),\n",
    "                include_top=False,\n",
    "                pretrained_top=False,\n",
    "                weights = 'imagenet21k'\n",
    "            )\n",
    "        elif self.model_tag == \"vit_b32\":\n",
    "            base_model = vit.vit_b32(\n",
    "                image_size=self.INPUT_SHAPE[0],\n",
    "                activation='softmax',\n",
    "                pretrained=(self.weights == \"imagenet\"),\n",
    "                include_top=False,\n",
    "                pretrained_top=False,\n",
    "                weights = 'imagenet21k'\n",
    "            )\n",
    "        elif self.model_tag == \"vit_l16\":\n",
    "            base_model = vit.vit_l16(\n",
    "                image_size=self.INPUT_SHAPE[0],\n",
    "                activation='softmax',\n",
    "                pretrained=(self.weights == \"imagenet\"),\n",
    "                include_top=False,\n",
    "                pretrained_top=False,\n",
    "                weights = 'imagenet21k'\n",
    "            )\n",
    "        elif self.model_tag == \"vit_l32\":\n",
    "            base_model = vit.vit_l32(\n",
    "                image_size=self.INPUT_SHAPE[0],\n",
    "                activation='softmax',\n",
    "                pretrained=(self.weights == \"imagenet\"),\n",
    "                include_top=False,\n",
    "                pretrained_top=False,\n",
    "                weights = 'imagenet21k'\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(self.ERR_MSG_MODEL_TAG)\n",
    "        \n",
    "        if self.freeze_bn:\n",
    "            for l in base_model.layers:\n",
    "                if type(l) is tf.keras.layers.BatchNormalization:\n",
    "                    l.trainable = False\n",
    "        \n",
    "        return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.542202Z",
     "iopub.status.busy": "2021-02-14T15:11:54.541450Z",
     "iopub.status.idle": "2021-02-14T15:11:54.568090Z",
     "shell.execute_reply": "2021-02-14T15:11:54.567141Z"
    },
    "papermill": {
     "duration": 0.059023,
     "end_time": "2021-02-14T15:11:54.568255",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.509232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\", dtype={\"image_id\": \"object\", \"label\": \"uint8\"})\n",
    "test_df = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\", dtype={\"image_id\": \"object\", \"label\": \"uint8\"})\n",
    "sample_submission = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022154,
     "end_time": "2021-02-14T15:11:54.612327",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.590173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Datasets Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.665303Z",
     "iopub.status.busy": "2021-02-14T15:11:54.664513Z",
     "iopub.status.idle": "2021-02-14T15:11:54.667374Z",
     "shell.execute_reply": "2021-02-14T15:11:54.666916Z"
    },
    "papermill": {
     "duration": 0.03297,
     "end_time": "2021-02-14T15:11:54.667497",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.634527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "    \n",
    "def display_items(ds, labeled = True, row = 6, col = 4):\n",
    "    for (img,label) in ds:\n",
    "        plt.figure(figsize=(15,int(15*row/col)))\n",
    "        for j in range(row*col):\n",
    "            _label = label[j, ].numpy()\n",
    "            if labeled:\n",
    "                _label = np.round(_label, 2)\n",
    "            else:\n",
    "                _label = _label.decode()\n",
    "            plt.subplot(row,col,j+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(str(_label))\n",
    "            if CFG[\"IMAGE_NORMALIZATION\"]: _img = inverse_preprocess_normalization(img[j, ])\n",
    "            else: _img = img[j, ]\n",
    "            plt.imshow(_img.numpy())\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.724373Z",
     "iopub.status.busy": "2021-02-14T15:11:54.723423Z",
     "iopub.status.idle": "2021-02-14T15:11:54.725797Z",
     "shell.execute_reply": "2021-02-14T15:11:54.726306Z"
    },
    "papermill": {
     "duration": 0.036264,
     "end_time": "2021-02-14T15:11:54.726444",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.690180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Augmentation用のクラス（single, mixそれぞれ）\n",
    "single_augment = SingleImageAugmentator(\n",
    "    seed = CFG[\"SEED\"],\n",
    "    RANDOM_FLIP_LEFT_RIGHT = CFG[\"RANDOM_FLIP_LEFT_RIGHT\"],\n",
    "    RANDOM_FLIP_UP_DOWN = CFG[\"RANDOM_FLIP_UP_DOWN\"],\n",
    "    RANDOM_ROTATION = CFG[\"RANDOM_ROTATION\"],\n",
    "    RANDOM_ROTATION_RANGE = CFG[\"RANDOM_ROTATION_RANGE\"],\n",
    "    RANDOM_ROTATION_FILL_MODE = CFG[\"RANDOM_ROTATION_FILL_MODE\"],\n",
    "    RANDOM_BRIGHTNESS = CFG[\"RANDOM_BRIGHTNESS\"],\n",
    "    RANDOM_BRIGHTNESS_MAX_DELTA = CFG[\"RANDOM_BRIGHTNESS_MAX_DELTA\"],\n",
    "    RANDOM_CONTRAST = CFG[\"RANDOM_CONTRAST\"],\n",
    "    RANDOM_CONTRAST_LOWER = CFG[\"RANDOM_CONTRAST_LOWER\"],\n",
    "    RANDOM_CONTRAST_UPPER = CFG[\"RANDOM_CONTRAST_UPPER\"],\n",
    "    RANDOM_HUE = CFG[\"RANDOM_HUE\"],\n",
    "    RANDOM_HUE_MAX_DELTA = CFG[\"RANDOM_HUE_MAX_DELTA\"],\n",
    "    RANDOM_SATURATION = CFG[\"RANDOM_SATURATION\"],\n",
    "    RANDOM_SATURATION_LOWER = CFG[\"RANDOM_SATURATION_LOWER\"],\n",
    "    RANDOM_SATURATION_UPPER = CFG[\"RANDOM_SATURATION_UPPER\"],\n",
    ")\n",
    "mix_augment = MixImageAugmentator(\n",
    "    seed = CFG[\"SEED\"],\n",
    "    AUG_BATCH = CFG[\"AUG_BATCH\"],\n",
    "    IMAGE_SIZE_0 = CFG[\"IMAGE_SIZE\"][0],\n",
    "    IMAGE_SIZE_1 = CFG[\"IMAGE_SIZE\"][1],\n",
    "    CHANNELS = CFG[\"CHANNELS\"],\n",
    "    CLASSES = CFG[\"NUM_CLASSES\"],\n",
    "    MIXUP_PROB = CFG[\"MIXUP_PROB\"],\n",
    "    MIXUP_ALPHA = CFG[\"MIXUP_ALPHA\"],\n",
    "    CUTMIX_PROB = CFG[\"CUTMIX_PROB\"],\n",
    "    CUTMIX_ALPHA = CFG[\"CUTMIX_ALPHA\"],\n",
    "    FMIX_PROB = CFG[\"FMIX_PROB\"],\n",
    "    FMIX_ALPHA = CFG[\"FMIX_ALPHA\"],\n",
    "    FMIX_DECAY = CFG[\"FMIX_DECAY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.778437Z",
     "iopub.status.busy": "2021-02-14T15:11:54.777668Z",
     "iopub.status.idle": "2021-02-14T15:11:54.780415Z",
     "shell.execute_reply": "2021-02-14T15:11:54.780904Z"
    },
    "papermill": {
     "duration": 0.032313,
     "end_time": "2021-02-14T15:11:54.781065",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.748752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_normalization(image):\n",
    "    \n",
    "    mean = tf.convert_to_tensor(CFG[\"NORMALIZATION_MEAN\"], dtype=tf.float32)\n",
    "    std = tf.convert_to_tensor(CFG[\"NORMALIZATION_STD\"], dtype=tf.float32)\n",
    "    \n",
    "    image = (image - mean)/std\n",
    "    \n",
    "    return image\n",
    "\n",
    "def inverse_preprocess_normalization(image):\n",
    "    \n",
    "    mean = tf.convert_to_tensor(CFG[\"NORMALIZATION_MEAN\"], dtype=tf.float32)\n",
    "    std = tf.convert_to_tensor(CFG[\"NORMALIZATION_STD\"], dtype=tf.float32)\n",
    "    \n",
    "    image = image * std + mean\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.844346Z",
     "iopub.status.busy": "2021-02-14T15:11:54.834407Z",
     "iopub.status.idle": "2021-02-14T15:11:54.846616Z",
     "shell.execute_reply": "2021-02-14T15:11:54.847191Z"
    },
    "papermill": {
     "duration": 0.043075,
     "end_time": "2021-02-14T15:11:54.847337",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.804262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, CFG[\"IMAGE_SIZE\"])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [*CFG[\"IMAGE_SIZE\"], CFG[\"CHANNELS\"]])\n",
    "    if CFG[\"IMAGE_NORMALIZATION\"]:\n",
    "        image = preprocess_normalization(image)\n",
    "    return image\n",
    "\n",
    "def onehot(image,label):\n",
    "    return image,tf.one_hot(label,CFG[\"NUM_CLASSES\"])\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = example[\"target\"]\n",
    "        return image, label\n",
    "    image_id = example['image_name']\n",
    "    return image, image_id\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(lambda x:read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(filenames, do_aug = True, do_mix_aug = True):\n",
    "    dataset = load_dataset(filenames, labeled = True, ordered = False)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(512, seed = CFG[\"SEED\"])\n",
    "    dataset = dataset.map(onehot, num_parallel_calls=AUTO)\n",
    "    if do_aug:\n",
    "        dataset = dataset.map(single_augment, num_parallel_calls=AUTO)\n",
    "    if do_mix_aug:\n",
    "        dataset = dataset.batch(CFG[\"AUG_BATCH\"])\n",
    "        dataset = dataset.map(mix_augment, num_parallel_calls=AUTO) # note we put AFTER batching\n",
    "        dataset = dataset.unbatch()\n",
    "    dataset = dataset.batch(CFG[\"BATCH_SIZE\"])\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(filenames):\n",
    "    dataset = load_dataset(filenames, labeled = True, ordered = True)\n",
    "    dataset = dataset.map(onehot, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(CFG[\"BATCH_SIZE\"])\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(filenames):\n",
    "    dataset = load_dataset(filenames, labeled = False, ordered = True)\n",
    "    dataset = dataset.batch(CFG[\"BATCH_SIZE\"])\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022286,
     "end_time": "2021-02-14T15:11:54.892228",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.869942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:54.943652Z",
     "iopub.status.busy": "2021-02-14T15:11:54.942908Z",
     "iopub.status.idle": "2021-02-14T15:11:54.946341Z",
     "shell.execute_reply": "2021-02-14T15:11:54.945582Z"
    },
    "papermill": {
     "duration": 0.031799,
     "end_time": "2021-02-14T15:11:54.946473",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.914674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = tf.keras.Input(INPUT_SHAPE)\n",
    "    base_model = BaseModel(\n",
    "        model_tag = CFG['MODEL_TAG'],\n",
    "        weights = None,\n",
    "        freeze_bn = CFG[\"FREEZE_BN\"],\n",
    "        input_shape = INPUT_SHAPE,\n",
    "    )()\n",
    "    \n",
    "    base = base_model(inputs)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(CFG[\"NUM_CLASSES\"])(base)\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs = inputs,\n",
    "        outputs = outputs,\n",
    "    )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022845,
     "end_time": "2021-02-14T15:11:54.992881",
     "exception": false,
     "start_time": "2021-02-14T15:11:54.970036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:55.050480Z",
     "iopub.status.busy": "2021-02-14T15:11:55.049695Z",
     "iopub.status.idle": "2021-02-14T15:11:55.053002Z",
     "shell.execute_reply": "2021-02-14T15:11:55.052389Z"
    },
    "papermill": {
     "duration": 0.037197,
     "end_time": "2021-02-14T15:11:55.053125",
     "exception": false,
     "start_time": "2021-02-14T15:11:55.015928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tfrecord_ids(example):\n",
    "    tfrecord_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image_id = example['image_name']\n",
    "    return image_id\n",
    "\n",
    "def get_ds_for_id(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.map(lambda x:read_tfrecord_ids(x), num_parallel_calls=AUTO)\n",
    "    dataset = dataset.batch(TEST_BATCH_SIZE)\n",
    "    return dataset\n",
    "    \n",
    "def get_ds_for_prediction(filenames):\n",
    "    do_aug = (CFG[\"DO_AUG\"] and (CFG[\"TTA\"] >= 2))\n",
    "    dataset = load_dataset(filenames, labeled = True, ordered = True)\n",
    "    dataset = dataset.repeat(CFG[\"TTA\"])\n",
    "    if do_aug: dataset = dataset.map(single_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.batch(TEST_BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def make_prediction(filenames, model):\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    id_ds = get_ds_for_id(filenames)\n",
    "    image_ids = np.concatenate([image_id.astype(\"str\") for image_id in id_ds.as_numpy_iterator()] * CFG[\"TTA\"])\n",
    "\n",
    "    dataset = get_ds_for_prediction(filenames)\n",
    "    preds = model.predict(dataset, verbose = 1)\n",
    "\n",
    "    result_df[\"image_id\"] = image_ids\n",
    "    for i in range(CFG[\"NUM_CLASSES\"]):\n",
    "        result_df[f\"label_{i}\"] = preds[:, i]\n",
    "    \n",
    "    result_df = result_df.groupby(\"image_id\").mean()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:11:55.104515Z",
     "iopub.status.busy": "2021-02-14T15:11:55.103902Z",
     "iopub.status.idle": "2021-02-14T15:12:21.632436Z",
     "shell.execute_reply": "2021-02-14T15:12:21.631888Z"
    },
    "papermill": {
     "duration": 26.556933,
     "end_time": "2021-02-14T15:12:21.632588",
     "exception": false,
     "start_time": "2021-02-14T15:11:55.075655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## fold 1/5 ##############################\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "############################## fold 2/5 ##############################\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "############################## fold 3/5 ##############################\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "############################## fold 4/5 ##############################\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "############################## fold 5/5 ##############################\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "CPU times: user 16.2 s, sys: 1.31 s, total: 17.5 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sub_prob = pd.DataFrame()\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "for fold in range(CFG[\"FOLDS\"]):\n",
    "    print(\"#\" * 30, f\"fold {fold + 1}/{CFG['FOLDS']}\", \"#\" * 30)\n",
    "    tf.keras.backend.clear_session()\n",
    "    weights_file_path = f\"weights_{CFG['MODEL_TAG']}_fold{fold}.h5\"\n",
    "\n",
    "    model.load_weights(os.path.join(INPUT_DIR, weights_file_path))\n",
    "\n",
    "    # make sub prediction\n",
    "    _preds = make_prediction(test_filenames, model)\n",
    "    sub_prob = pd.concat([sub_prob, _preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:12:21.699479Z",
     "iopub.status.busy": "2021-02-14T15:12:21.698631Z",
     "iopub.status.idle": "2021-02-14T15:12:21.712400Z",
     "shell.execute_reply": "2021-02-14T15:12:21.713013Z"
    },
    "papermill": {
     "duration": 0.05191,
     "end_time": "2021-02-14T15:12:21.713196",
     "exception": false,
     "start_time": "2021-02-14T15:12:21.661286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>-0.815305</td>\n",
       "      <td>-0.370056</td>\n",
       "      <td>1.159971</td>\n",
       "      <td>-1.831684</td>\n",
       "      <td>1.691907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>-1.279220</td>\n",
       "      <td>-0.633256</td>\n",
       "      <td>2.010140</td>\n",
       "      <td>-1.904642</td>\n",
       "      <td>1.533733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>-1.062366</td>\n",
       "      <td>-0.645648</td>\n",
       "      <td>1.112429</td>\n",
       "      <td>-1.065102</td>\n",
       "      <td>1.698140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>-1.107527</td>\n",
       "      <td>-0.105813</td>\n",
       "      <td>1.738636</td>\n",
       "      <td>-1.896744</td>\n",
       "      <td>1.971731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>-0.704563</td>\n",
       "      <td>-0.697859</td>\n",
       "      <td>1.349013</td>\n",
       "      <td>-1.480617</td>\n",
       "      <td>1.700505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label_0   label_1   label_2   label_3   label_4\n",
       "image_id                                                        \n",
       "2216849948.jpg -0.815305 -0.370056  1.159971 -1.831684  1.691907\n",
       "2216849948.jpg -1.279220 -0.633256  2.010140 -1.904642  1.533733\n",
       "2216849948.jpg -1.062366 -0.645648  1.112429 -1.065102  1.698140\n",
       "2216849948.jpg -1.107527 -0.105813  1.738636 -1.896744  1.971731\n",
       "2216849948.jpg -0.704563 -0.697859  1.349013 -1.480617  1.700505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:12:21.796635Z",
     "iopub.status.busy": "2021-02-14T15:12:21.795720Z",
     "iopub.status.idle": "2021-02-14T15:12:21.915239Z",
     "shell.execute_reply": "2021-02-14T15:12:21.914685Z"
    },
    "papermill": {
     "duration": 0.164284,
     "end_time": "2021-02-14T15:12:21.915383",
     "exception": false,
     "start_time": "2021-02-14T15:12:21.751099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_prob = sub_prob.groupby(\"image_id\").mean()\n",
    "sub_prob.to_csv(\"submission_probabilities.csv\")\n",
    "sub = sub_prob.copy()\n",
    "sub[\"label\"] = np.argmax(sub_prob.values, axis = 1)\n",
    "sub = sub[[\"label\"]]\n",
    "sub.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:12:21.984262Z",
     "iopub.status.busy": "2021-02-14T15:12:21.983533Z",
     "iopub.status.idle": "2021-02-14T15:12:21.987132Z",
     "shell.execute_reply": "2021-02-14T15:12:21.987601Z"
    },
    "papermill": {
     "duration": 0.042637,
     "end_time": "2021-02-14T15:12:21.987747",
     "exception": false,
     "start_time": "2021-02-14T15:12:21.945110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2216849948.jpg</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                label\n",
       "image_id             \n",
       "2216849948.jpg      4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-14T15:12:22.056199Z",
     "iopub.status.busy": "2021-02-14T15:12:22.054962Z",
     "iopub.status.idle": "2021-02-14T15:12:22.058980Z",
     "shell.execute_reply": "2021-02-14T15:12:22.058438Z"
    },
    "papermill": {
     "duration": 0.041409,
     "end_time": "2021-02-14T15:12:22.059106",
     "exception": false,
     "start_time": "2021-02-14T15:12:22.017697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"configuration.json\"), \"w\") as f:\n",
    "    json.dump(CFG, f)\n",
    "    \n",
    "with open(os.path.join(OUTPUT_DIR, \"result.json\"), \"w\") as f:\n",
    "    json.dump(RESULT, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 181.750288,
   "end_time": "2021-02-14T15:12:25.550446",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-14T15:09:23.800158",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
